{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bc4beeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c79e6843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25ec671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake=pd.read_csv('../data/Fake.csv')\n",
    "real=pd.read_csv('../data/True.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6118beaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake['label']='fake'\n",
    "real['label']='real'\n",
    "\n",
    "df = pd.concat([fake, real]).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f0333ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title      44898\n",
       "text       44898\n",
       "subject    44898\n",
       "date       44898\n",
       "label      44898\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5f63ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f214c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spacy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove non-alphabetic characters (keep spaces)\n",
    "    text = re.sub(r'[^a-zA-Z ]', '', text)\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Remove stopwords using nltk\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    # Lemmatization using spacy\n",
    "    doc = nlp(text)\n",
    "    text = ' '.join([token.lemma_ for token in doc])\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31dc3234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_title</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>processed_subject</th>\n",
       "      <th>processed_date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lindsey graham call party say republicans be n...</td>\n",
       "      <td>sc senator lindsey graham shine beacon republi...</td>\n",
       "      <td>news</td>\n",
       "      <td>january</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trump take second crack pivot next week appren...</td>\n",
       "      <td>washington reuters president donald trump beco...</td>\n",
       "      <td>politicsnew</td>\n",
       "      <td>june</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saudi king say kingdom make progress tackle te...</td>\n",
       "      <td>mecca saudi arabia reuters saudi king salman r...</td>\n",
       "      <td>worldnew</td>\n",
       "      <td>september</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trump support republican tax overhaul bill adv...</td>\n",
       "      <td>washington reuters us president donald trump s...</td>\n",
       "      <td>politicsnew</td>\n",
       "      <td>november</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>boom clinton rap pay foundation key nation video</td>\n",
       "      <td></td>\n",
       "      <td>politic</td>\n",
       "      <td>nov</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     processed_title  \\\n",
       "0  lindsey graham call party say republicans be n...   \n",
       "1  trump take second crack pivot next week appren...   \n",
       "2  saudi king say kingdom make progress tackle te...   \n",
       "3  trump support republican tax overhaul bill adv...   \n",
       "4   boom clinton rap pay foundation key nation video   \n",
       "\n",
       "                                      processed_text processed_subject  \\\n",
       "0  sc senator lindsey graham shine beacon republi...              news   \n",
       "1  washington reuters president donald trump beco...       politicsnew   \n",
       "2  mecca saudi arabia reuters saudi king salman r...          worldnew   \n",
       "3  washington reuters us president donald trump s...       politicsnew   \n",
       "4                                                              politic   \n",
       "\n",
       "  processed_date label  \n",
       "0        january  fake  \n",
       "1           june  real  \n",
       "2      september  real  \n",
       "3       november  real  \n",
       "4            nov  fake  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run preprocessing on all samples\n",
    "df['processed_title'] = df['title'].apply(preprocess_text)\n",
    "df['processed_text'] = df['text'].apply(preprocess_text)\n",
    "df['processed_subject'] = df['subject'].apply(preprocess_text)\n",
    "df['processed_date'] = df['date'].astype(str).apply(preprocess_text)\n",
    "\n",
    "processed_df = df[['processed_title', 'processed_text', 'processed_subject', 'processed_date', 'label']]\n",
    "\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aee31b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22058/3027024622.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed_df['tokens_title'] = processed_df['processed_title'].apply(word_tokenize)\n",
      "/tmp/ipykernel_22058/3027024622.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed_df['tokens_text'] = processed_df['processed_text'].apply(word_tokenize)\n",
      "/tmp/ipykernel_22058/3027024622.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed_df['tokens_text'] = processed_df['processed_text'].apply(word_tokenize)\n",
      "/tmp/ipykernel_22058/3027024622.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed_df['tokens_subject'] = processed_df['processed_subject'].apply(word_tokenize)\n",
      "/tmp/ipykernel_22058/3027024622.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed_df['tokens_subject'] = processed_df['processed_subject'].apply(word_tokenize)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens_title</th>\n",
       "      <th>tokens_text</th>\n",
       "      <th>tokens_subject</th>\n",
       "      <th>tokens_date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[lindsey, graham, call, party, say, republican...</td>\n",
       "      <td>[sc, senator, lindsey, graham, shine, beacon, ...</td>\n",
       "      <td>[news]</td>\n",
       "      <td>[january]</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[trump, take, second, crack, pivot, next, week...</td>\n",
       "      <td>[washington, reuters, president, donald, trump...</td>\n",
       "      <td>[politicsnew]</td>\n",
       "      <td>[june]</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[saudi, king, say, kingdom, make, progress, ta...</td>\n",
       "      <td>[mecca, saudi, arabia, reuters, saudi, king, s...</td>\n",
       "      <td>[worldnew]</td>\n",
       "      <td>[september]</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[trump, support, republican, tax, overhaul, bi...</td>\n",
       "      <td>[washington, reuters, us, president, donald, t...</td>\n",
       "      <td>[politicsnew]</td>\n",
       "      <td>[november]</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[boom, clinton, rap, pay, foundation, key, nat...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[politic]</td>\n",
       "      <td>[nov]</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        tokens_title  \\\n",
       "0  [lindsey, graham, call, party, say, republican...   \n",
       "1  [trump, take, second, crack, pivot, next, week...   \n",
       "2  [saudi, king, say, kingdom, make, progress, ta...   \n",
       "3  [trump, support, republican, tax, overhaul, bi...   \n",
       "4  [boom, clinton, rap, pay, foundation, key, nat...   \n",
       "\n",
       "                                         tokens_text tokens_subject  \\\n",
       "0  [sc, senator, lindsey, graham, shine, beacon, ...         [news]   \n",
       "1  [washington, reuters, president, donald, trump...  [politicsnew]   \n",
       "2  [mecca, saudi, arabia, reuters, saudi, king, s...     [worldnew]   \n",
       "3  [washington, reuters, us, president, donald, t...  [politicsnew]   \n",
       "4                                                 []      [politic]   \n",
       "\n",
       "   tokens_date label  \n",
       "0    [january]  fake  \n",
       "1       [june]  real  \n",
       "2  [september]  real  \n",
       "3   [november]  real  \n",
       "4        [nov]  fake  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Tokenize processed columns in the sample dataframe\n",
    "processed_df['tokens_title'] = processed_df['processed_title'].apply(word_tokenize)\n",
    "processed_df['tokens_text'] = processed_df['processed_text'].apply(word_tokenize)\n",
    "processed_df['tokens_subject'] = processed_df['processed_subject'].apply(word_tokenize)\n",
    "processed_df['tokens_date'] = processed_df['processed_date'].apply(word_tokenize)\n",
    "\n",
    "# Display tokenized sample\n",
    "processed_df[['tokens_title', 'tokens_text', 'tokens_subject', 'tokens_date', 'label']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9008f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Join tokens back to string for vectorization\n",
    "processed_df['text_for_vectorizer'] = processed_df['tokens_text'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "# Vectorize the text\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(processed_df['text_for_vectorizer'])\n",
    "y = processed_df['label'].map({'fake': 0, 'real': 1})  # Encode labels\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(class_weight='balanced',max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save vectorizer and model to disk\n",
    "with open('vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Evaluate model\n",
    "score = model.score(X_test, y_test)\n",
    "print(f\"Test Accuracy: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1613232a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
